{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basics_parsing_and_API.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMX5jIEfqlqhSG90jW+xuac",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GezhinOleg/Num_Pnd_L7/blob/main/Basics_parsing_and_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85sds5iscb1"
      },
      "source": [
        "## Задание 1.\n",
        "\n",
        "Обязательная часть Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
        "\n",
        "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
        "\n",
        "KEYWORDS = [‘python’, ‘парсинг’]\n",
        "\n",
        "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
        "\n",
        "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>\n",
        "\n",
        "Дополнительная часть (необязательная) Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
        "\n",
        "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
        "\n",
        "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст_статьи>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGZa8277rVU7"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClDGX_wFszzI"
      },
      "source": [
        "KEYWORDS = {'python',  'парсинг'}\n",
        "BASEURL = 'https://habr.com/ru/all/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5eRVvQhtLhL"
      },
      "source": [
        "def get_url_text(url):\n",
        "    response = requests.get(url)\n",
        "    if response.ok:\n",
        "        return response.text\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkV21kMUtRon"
      },
      "source": [
        "def main(url=BASEURL):\n",
        "    text = get_url_text(url)\n",
        "    soup = bs(text, features='html.parser')\n",
        "    articles = soup.find_all('article')\n",
        "    article_list = []\n",
        "    for article in articles:\n",
        "        article_time = article.find('span', class_='tm-article-snippet__datetime-published').text\n",
        "        # Получаем время написания статьи\n",
        "        article_title = article.find('a', class_='tm-article-snippet__title-link')\n",
        "        # Получаем текст лежащий между тегами <a></a>\n",
        "        article_title_link = article_title['href']\n",
        "        # Получаем текст сокращенной ссылки\n",
        "        hubs = [h.text.strip() for h in article.find_all('a', class_='tm-article-snippet__title-link')]\n",
        "        st_list = hubs[0].lower().split()\n",
        "        # Буквы полученного текста приводим к строчному представлению, чтобы не упустить слова из-за написания\n",
        "        for st in st_list:\n",
        "            if st in KEYWORDS:\n",
        "                text = ''.join(hubs)\n",
        "                article_list.append(f\"{article_time} - {text} - https://habr.com{article_title_link}\")\n",
        "    return article_list\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2-1pGGctWOf",
        "outputId": "f053cfaf-564b-4f78-f9be-9e3786a504b2"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    output_list = []\n",
        "    pages = int(input('Введите количество страниц: '))\n",
        "    for page in range(pages):\n",
        "        print(f'Обрабатываем страницу {page + 1} из {pages}')\n",
        "        if page == 0:\n",
        "            output_list += main()\n",
        "        else:\n",
        "            output_list += main(url=f'{BASEURL}page{page+1}/')\n",
        "    print(*output_list, sep='\\n')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Введите количество страниц: 3\n",
            "Обрабатываем страницу 1 из 3\n",
            "Обрабатываем страницу 2 из 3\n",
            "Обрабатываем страницу 3 из 3\n",
            "20  августа   в 16:21 - predict_proba в Python не прогнозирует вероятности (и как с этим бороться) - https://habr.com/ru/company/otus/blog/573924/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E5U48pnu1_e"
      },
      "source": [
        "## Задание 2.\n",
        "\n",
        "Обязательная часть Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода: EMAIL = [xxx@x.ru, yyy@y.com]\n",
        "\n",
        "В итоге должен формироваться датафрейм со столбцами: <дата утечки> - <источник утечки> - <описание утечки>\n",
        "\n",
        "Подсказка: сервис работает при помощи “скрытого” API. Внимательно изучите post-запросы.\n",
        "\n",
        "Дополнительная часть (необязательная) Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте. Документация к API VK: https://vk.com/dev/methods , вам поможет метод wall.get\n",
        "\n",
        "GROUP = 'netology’ TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ В итоге должен формироваться датафрейм со столбцами: <дата поста> - <текст поста>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMyFTjlDvRXR"
      },
      "source": [
        "import requests\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWynH2fNvWYe"
      },
      "source": [
        "url = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
        "headers = {'Accept': 'application/json, text/plain, */*',\n",
        "        'Accept-Encoding': 'gzip, deflate, br',\n",
        "        'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',\n",
        "        'Connection': 'keep-alive',\n",
        "        'Content-Type': 'application/json;charset=UTF-8',\n",
        "        'Host': 'identityprotection.avast.com',\n",
        "        'Origin': 'https://www.avast.com',\n",
        "        'Referer': 'https://www.avast.com/',\n",
        "        'sec-ch-ua': '\"Chromium\";v=\"92\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"92\"',\n",
        "        'sec-ch-ua-mobile': '?0',\n",
        "        'Sec-Fetch-Dest': 'empty',\n",
        "        'Sec-Fetch-Mode': 'cors',\n",
        "        'Sec-Fetch-Site': 'same-site',\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36',\n",
        "        'Vaar-Header-App-Build-Version': '1.0.0',\n",
        "        'Vaar-Header-App-Product': 'hackcheck-web-avast',\n",
        "        'Vaar-Header-App-Product-Name': 'hackcheck-web-avast',\n",
        "        'Vaar-Version': '0',\n",
        "        'Access-Control-Allow-Credentials': 'true',\n",
        "        'Access-Control-Allow-Methods': 'POST',\n",
        "        'Access-Control-Allow-Origin': 'https://www.avast.com',\n",
        "        'Access-Control-Expose-Headers': 'Vaar-Version, Vaar-Status',\n",
        "        'Access-Control-Max-Age': '86400',\n",
        "        'Connection': 'keep-alive',\n",
        "        'Content-Type': 'application/json',\n",
        "        'Server': 'nginx',\n",
        "        'Vaar-Header-Execution-Chain-Id': '3224d669-242b-47c2-bcba-689443db864d',\n",
        "        'Vaar-Status': '0',\n",
        "        'Vaar-Version': '0',\n",
        "        'Vary': 'Origin,Access-Control-Request-Method'\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSJHR1QKvcfy"
      },
      "source": [
        "def load_data():\n",
        "    email_input = input('Введите через пробел e-mail, и нажмите \"Enter\"').split()\n",
        "    payload = json.dumps({'emailAddresses': email_input})\n",
        "    s = requests.post(url, headers=headers, data=payload)\n",
        "    with open('outfile.txt', 'w', encoding='utf-8') as out_file:\n",
        "        out_file.write(s.text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzHbLuXIvkp4"
      },
      "source": [
        "def edit_data():\n",
        "    with open('mail_list.txt', 'w', encoding='utf-8') as m_file:\n",
        "        m_file.write('')\n",
        "    with open('outfile.txt', 'r', encoding='utf-8') as f:\n",
        "        file = f.readline()\n",
        "        dict_file = json.loads(file)\n",
        "        for i in dict_file['breaches']:\n",
        "            leak_date = dict_file['breaches'][i]['publishDate']\n",
        "            leak_description = dict_file['breaches'][i]['description']\n",
        "            leak_source = dict_file['breaches'][i]['site']\n",
        "            mail_str = (f'{leak_date} - {leak_source} - {leak_description}' + '\\n')\n",
        "            with open('mail_list.txt', 'a', encoding='utf-8') as m_file:\n",
        "                m_file.write(mail_str)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DybE2zi0vphs"
      },
      "source": [
        "def main():\n",
        "    call = input('Для проверки e-mail, введите 1, для вывода результата проверки введите 2: ')\n",
        "    if call == '1':\n",
        "        load_data()\n",
        "    elif call == '2':\n",
        "        edit_data()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "        main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}